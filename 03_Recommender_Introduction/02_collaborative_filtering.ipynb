{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To open this notebook in Google Colab and start coding, click on the Colab icon below.\n",
    "\n",
    "<table style=\"border:2px solid orange\" align=\"left\">\n",
    "    <td style=\"border:2px solid orange\">\n",
    "        <a target=\"_blank\" href=\"https://colab.research.google.com/github/neuefische/ds-meetups/blob/main/03_Recommender_Introduction/02_collaborative_filtering.ipynb\">\n",
    "        <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "    </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run on colab\n",
    "!pip install surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative filtering\n",
    "\n",
    "In this notebook you will learn about collaborative filtering and how to implement it with the surprise library. Collaborative filtering is a collective term for different recommendation algorithms based on user behavior. Those algorithm find users similar to each other based on their rating or clicking history. The interactions between users and items are stored in a so-called \"user-item interactions matrix\". These interactions can be explicit like actively giving ratings or implicit like click-data. In general there are two popular types of collaborative filtering approaches. The user-based filtering and the item-based filtering.\n",
    "\n",
    "User-based filtering algorithms predict ratings based on the ratings from similar (in terms of rating) users.</br>\n",
    "Item-based filtering algorithms predict ratings based on the ratings of similar (in terms of rating) items. Item-based models are especially used when you have way more users than items. Those models use average rating per item and not per user.\n",
    "\n",
    "A typical example of a problem collaborative filtering is trying to solve is the following: We have users, who rated specific items but a lot of item were not rated yet. We then try to predict the missing ratings denoted by red fields in this example of a user-item rating matrix.\n",
    "\n",
    "<p align = \"center\">\n",
    "<img src = \"./images/UserItemRatingMatrix.png\">\n",
    "</p>\n",
    "<p align = \"center\">\n",
    "Fig.1 - User-Item-Rating Matrix - icons are from Vecteezy.com\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import KNNWithMeans, SVD\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our rating data. It contains the necessary `user_id`, `item_id` and the `rating` users gave to the fish items. Additionally it has some nice-to-have information about the fish items. There are 500 users with 300 rated fishes each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset from github may take some minutes -> coffee time :)\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/neuefische/ds-meetups/recommender_aljoscha/03_recommender/user_item_ratings.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Surprise library we want to use does not work with pandas DataFrames but with Dataset objects. So we need to create a Dataset object from our DataFrame. We also need to define the possible ratings with the Reader class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines possible ratings\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "# Loads Pandas dataframe\n",
    "data = Dataset.load_from_df(df[[\"user_id\", \"item_id\", \"rating\"]], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to validate our models we need to split our data into a trainset, which we will use to train our models. And a testset to validate the ability of our models to predict on unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest-Neighbors\n",
    "\n",
    "One of the most common models for collaborative filtering is the K-nearest neighbor algorithm (KNN). KNN is a non-prarmetric, lazy learning method. Lazy because it just stores the the data-points  without learning any kind of coefficient. To make predictions it calculates the \"distance\" between the target and every other instance, then it ranks the distances and returns the top K who are closest and therefore most similar to a given data point. Several ways exist to calculate the distances between the target and the other observations.</br>\n",
    "As KNN's performance suffers from curse of dimensionality and e.g. euclidean distance is not optimal in high dimensions, cosine similarity is the most popular distance measure in terms of multi-dimensional data. Further description of the cosine similarity can be found in notebook 1. In thies notebook we will use the [KNNWithMeans](https://surprise.readthedocs.io/en/stable/knn_inspired.html) algorithm implemented in the surprise library. This algorithm is directly derived from KNN but also takes the mean ratings of each user into account. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {\n",
    "    \"name\": \"cosine\",   # Use Cosine-Similarity\n",
    "    \"user_based\": False,  # Compute  similarities between items\n",
    "}\n",
    "algo = KNNWithMeans(sim_options=sim_options)\n",
    "algo.fit(trainset)\n",
    "\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition\n",
    "\n",
    "Another way to estimate the user ratings is Singular Value Decomposition (SVD). Singular value decomposition is a matrix decomposition, where we decompose a given m x n matrix $A$ into three matrices $U$, $\\Sigma$ and $V$ with the dimensions m x r, r x r and n x r respectively. Here r is usually small compared to m and n. And $\\Sigma$ is non zero only on the diagonal.\n",
    "\n",
    "![](./images/SVD_USigmaV.png) \n",
    "\n",
    "By decomposing the matrix $A$ in this way, we drastically reduce the number of elements to be stored. Let $m = n = 100$ and $r = 5$ then the original matrix $A$ has $100 \\times 100 = 10000$ elements. Whereas $U$ has $100 \\times 5 = 500$, $\\Sigma$ has $5$ (only diagonal elements) and $V$ again has $100 \\times 5 = 500$ elements leading to a total of only $1005$ elements as opposed to the $10000$ elements of the original matrix $A$.\n",
    "\n",
    "The rows of m of our user-item-rating matrix $A$ refer to the users and the n columns to the items (fishes in our case). The introduced latent factors r can be interpreted as characteristics of the users for $U$ and item characteristics for $V$. In our case they can tell us how much a user likes a certain `visual_effect` or how much a fish shows said `visual_effect` respectively. $\\Sigma$ then models the importance of each `visual_effect`.\n",
    "\n",
    "The actual implementation of the algorithm in the surprise library will be outlined here to show an example of how to find an optimal decomposition. It became popular due to Simon Funk and his contribution to the Netflix competition. Here the rating user u gives item i is denoted by $r_{ui}$ and will be estimated by\n",
    "\n",
    "$$\n",
    "\\hat r_{ui} = \\mu + b_u + b_i + q^T_i p_u\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "- (u,i): user-item pair\n",
    "- $\\mu$: average rating of all items\n",
    "- $b_i$: average rating of item i minus $\\mu$\n",
    "- $b_u$: average rating given by user u minus $\\mu$\n",
    "- $p_u$: latent user factor vector\n",
    "- $q_i$: latent item factor vector\n",
    "\n",
    "The parameters $b_i$, $b_u$, $p_u$ and $q_i$ are determined by minimizing the regularized squared error:\n",
    "\n",
    "$$\n",
    "\\sum_{r_{ui} \\in R_{train}}(r_{ui} - \\hat r_{ui})^2 + \\lambda(b_i^2 + b_u^2 + ||q_i||^2 + ||p_u||^2)\n",
    "$$\n",
    "\n",
    "The minimization is performed by a simple stochastic gradient descent (parameters are updated iteratively):\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "b_u &\\leftarrow b_u + \\gamma(e_{ui} - \\lambda b_u)\\\\\n",
    "b_i &\\leftarrow b_i + \\gamma(e_{ui} - \\lambda b_i)\\\\\n",
    "p_u &\\leftarrow p_u + \\gamma(e_{ui}*q_i - \\lambda p_u)\\\\\n",
    "q_i &\\leftarrow q_i + \\gamma(e_{ui}*p_u - \\lambda q_i)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $e_{ui} = r_{ui} - \\hat r_{ui}$, $\\gamma$ is the learning rate and $\\lambda$ is the regularization parameter.\n",
    "\n",
    "Now that we understand SVD let us train the algorithm on our train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the top 10 recommendations for a specific user. Though there is no implementation of this in surprise the documentation provides a function `get_top_n` that returns the top-N recommendations, if we provide the predictions of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we will get is a list of ten tuples (item_id, estimated_rating). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = get_top_n(predictions, n=10)   # top 10 recommendations for each user\n",
    "user_id = 201   # the user we want the recommendations for\n",
    "top_10[user_id]  # ten best rated items for user id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's make list of the top 10 item id's `top_iids`. And use it with the original fishes dataframe to get some characteristics of our recommended fishes. Apparently our user liked especially colorful fishes the most :) sorry for the spaghetti in line 2 xD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_iids = [id_est[0] for id_est in top_n[201]]\n",
    "recommended_fishes = df.set_index('item_id').loc[top_iids][['name','fish_group','visual_effect']].drop_duplicates()\n",
    "recommended_fishes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Grid Search\n",
    "\n",
    "The SVD algorithm in the surprise library comes with a lot of hyper parameters which influence the performance of the model. To search for optimal hyper parameters in machine learning Grid search is used. It performs an exhaustive search over a prior defined parameter space using cross-validation (hence the CV suffix). That means it will evaluate all of the possible parameter combinations of the search space in order to find and return the best combination.\n",
    "\n",
    "This task, however, starts to become very time-consuming if there are many hyperparameters and the search space is huge. As you can see for cv= 3 (number of folds that will be evaluated) and for 3 parameters with 2 values, thus 8 combinations, the GridSearchCV runs 24 modelling steps in order to just come up with the best values for the two parameters.\n",
    "\n",
    "Please feel free to try out different values and beat the default ones from our prediction above ;) and if you still have time improve your result even further!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_epochs\": [10, 20],       # The number of iteration of the SGD procedure. Default is 20.\n",
    "    \"lr_all\": [0.002, 0.005],   # The learning rate for all parameters. Default is 0.005.\n",
    "    \"reg_all\": [0.02, 0.04]     # The regularization term for all parameters. Default is 0.02.\n",
    "}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score[\"rmse\"])\n",
    "print(gs.best_params[\"rmse\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57aa640bf977b65fca8495e566ef2fbca9bcb146ab71fac5e6ffd89ab217633c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
